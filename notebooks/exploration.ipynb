{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba77808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "from src.data_ingestion import *\n",
    "from src.data_preprocessing import *\n",
    "from src.descriptive_analytics import *\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import NumericType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256eacb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Severity: integer (nullable = true)\n",
      " |-- Start_Time: timestamp (nullable = true)\n",
      " |-- End_Time: timestamp (nullable = true)\n",
      " |-- Start_Lat: double (nullable = true)\n",
      " |-- Start_Lng: double (nullable = true)\n",
      " |-- End_Lat: double (nullable = true)\n",
      " |-- End_Lng: double (nullable = true)\n",
      " |-- Distance(mi): double (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Street: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Timezone: string (nullable = true)\n",
      " |-- Airport_Code: string (nullable = true)\n",
      " |-- Weather_Timestamp: timestamp (nullable = true)\n",
      " |-- Temperature(F): double (nullable = true)\n",
      " |-- Wind_Chill(F): double (nullable = true)\n",
      " |-- Humidity(%): double (nullable = true)\n",
      " |-- Pressure(in): double (nullable = true)\n",
      " |-- Visibility(mi): double (nullable = true)\n",
      " |-- Wind_Direction: string (nullable = true)\n",
      " |-- Wind_Speed(mph): double (nullable = true)\n",
      " |-- Precipitation(in): double (nullable = true)\n",
      " |-- Weather_Condition: string (nullable = true)\n",
      " |-- Amenity: boolean (nullable = true)\n",
      " |-- Bump: boolean (nullable = true)\n",
      " |-- Crossing: boolean (nullable = true)\n",
      " |-- Give_Way: boolean (nullable = true)\n",
      " |-- Junction: boolean (nullable = true)\n",
      " |-- No_Exit: boolean (nullable = true)\n",
      " |-- Railway: boolean (nullable = true)\n",
      " |-- Roundabout: boolean (nullable = true)\n",
      " |-- Station: boolean (nullable = true)\n",
      " |-- Stop: boolean (nullable = true)\n",
      " |-- Traffic_Calming: boolean (nullable = true)\n",
      " |-- Traffic_Signal: boolean (nullable = true)\n",
      " |-- Turning_Loop: boolean (nullable = true)\n",
      " |-- Sunrise_Sunset: string (nullable = true)\n",
      " |-- Civil_Twilight: string (nullable = true)\n",
      " |-- Nautical_Twilight: string (nullable = true)\n",
      " |-- Astronomical_Twilight: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "df = load_data(spark)\n",
    "df.printSchema()\n",
    "# df.show(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c63b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values = check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c811fc",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2ff6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Checking for Missing Values...\n",
      "Missing Values Percentage by Column (Sorted):\n",
      "End_Lat: 44.03%\n",
      "End_Lng: 44.03%\n",
      "Precipitation(in): 28.51%\n",
      "Wind_Chill(F): 25.87%\n",
      "Wind_Speed(mph): 7.39%\n",
      "Visibility(mi): 2.29%\n",
      "Wind_Direction: 2.27%\n",
      "Humidity(%): 2.25%\n",
      "Weather_Condition: 2.24%\n",
      "Temperature(F): 2.12%\n",
      "Pressure(in): 1.82%\n",
      "Weather_Timestamp: 1.56%\n",
      "Sunrise_Sunset: 0.30%\n",
      "Civil_Twilight: 0.30%\n",
      "Nautical_Twilight: 0.30%\n",
      "Astronomical_Twilight: 0.30%\n",
      "Airport_Code: 0.29%\n",
      "Street: 0.14%\n",
      "Timezone: 0.10%\n",
      "Zipcode: 0.02%\n",
      "City: 0.00%\n",
      "Description: 0.00%\n",
      "ID: 0.00%\n",
      "Source: 0.00%\n",
      "Severity: 0.00%\n",
      "Start_Time: 0.00%\n",
      "End_Time: 0.00%\n",
      "Start_Lat: 0.00%\n",
      "Start_Lng: 0.00%\n",
      "Distance(mi): 0.00%\n",
      "County: 0.00%\n",
      "State: 0.00%\n",
      "Country: 0.00%\n",
      "Amenity: 0.00%\n",
      "Bump: 0.00%\n",
      "Crossing: 0.00%\n",
      "Give_Way: 0.00%\n",
      "Junction: 0.00%\n",
      "No_Exit: 0.00%\n",
      "Railway: 0.00%\n",
      "Roundabout: 0.00%\n",
      "Station: 0.00%\n",
      "Stop: 0.00%\n",
      "Traffic_Calming: 0.00%\n",
      "Traffic_Signal: 0.00%\n",
      "Turning_Loop: 0.00%\n",
      "\n",
      "Step 2: Replacing NaN values with None...\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"isnan(Start_Time)\" due to data type mismatch: Parameter 1 requires the (\"DOUBLE\" or \"FLOAT\") type, however \"Start_Time\" has the type \"TIMESTAMP\".;\n'Project [CASE WHEN isnan(cast(ID#0 as double)) THEN cast(null as string) ELSE ID#0 END AS ID#466, CASE WHEN isnan(cast(Source#1 as double)) THEN cast(null as string) ELSE Source#1 END AS Source#467, CASE WHEN isnan(cast(Severity#2 as double)) THEN cast(null as int) ELSE Severity#2 END AS Severity#468, CASE WHEN isnan(Start_Time#3) THEN null ELSE Start_Time#3 END AS Start_Time#469, CASE WHEN isnan(End_Time#4) THEN null ELSE End_Time#4 END AS End_Time#470, CASE WHEN isnan(Start_Lat#5) THEN cast(null as double) ELSE Start_Lat#5 END AS Start_Lat#471, CASE WHEN isnan(Start_Lng#6) THEN cast(null as double) ELSE Start_Lng#6 END AS Start_Lng#472, CASE WHEN isnan(End_Lat#7) THEN cast(null as double) ELSE End_Lat#7 END AS End_Lat#473, CASE WHEN isnan(End_Lng#8) THEN cast(null as double) ELSE End_Lng#8 END AS End_Lng#474, CASE WHEN isnan(Distance(mi)#9) THEN cast(null as double) ELSE Distance(mi)#9 END AS Distance(mi)#475, CASE WHEN isnan(cast(Description#10 as double)) THEN cast(null as string) ELSE Description#10 END AS Description#476, CASE WHEN isnan(cast(Street#11 as double)) THEN cast(null as string) ELSE Street#11 END AS Street#477, CASE WHEN isnan(cast(City#12 as double)) THEN cast(null as string) ELSE City#12 END AS City#478, CASE WHEN isnan(cast(County#13 as double)) THEN cast(null as string) ELSE County#13 END AS County#479, CASE WHEN isnan(cast(State#14 as double)) THEN cast(null as string) ELSE State#14 END AS State#480, CASE WHEN isnan(cast(Zipcode#15 as double)) THEN cast(null as string) ELSE Zipcode#15 END AS Zipcode#481, CASE WHEN isnan(cast(Country#16 as double)) THEN cast(null as string) ELSE Country#16 END AS Country#482, CASE WHEN isnan(cast(Timezone#17 as double)) THEN cast(null as string) ELSE Timezone#17 END AS Timezone#483, CASE WHEN isnan(cast(Airport_Code#18 as double)) THEN cast(null as string) ELSE Airport_Code#18 END AS Airport_Code#484, CASE WHEN isnan(Weather_Timestamp#19) THEN null ELSE Weather_Timestamp#19 END AS Weather_Timestamp#485, CASE WHEN isnan(Temperature(F)#20) THEN cast(null as double) ELSE Temperature(F)#20 END AS Temperature(F)#486, CASE WHEN isnan(Wind_Chill(F)#21) THEN cast(null as double) ELSE Wind_Chill(F)#21 END AS Wind_Chill(F)#487, CASE WHEN isnan(Humidity(%)#22) THEN cast(null as double) ELSE Humidity(%)#22 END AS Humidity(%)#488, CASE WHEN isnan(Pressure(in)#23) THEN cast(null as double) ELSE Pressure(in)#23 END AS Pressure(in)#489, ... 22 more fields]\n+- Relation [ID#0,Source#1,Severity#2,Start_Time#3,End_Time#4,Start_Lat#5,Start_Lng#6,End_Lat#7,End_Lng#8,Distance(mi)#9,Description#10,Street#11,City#12,County#13,State#14,Zipcode#15,Country#16,Timezone#17,Airport_Code#18,Weather_Timestamp#19,Temperature(F)#20,Wind_Chill(F)#21,Humidity(%)#22,Pressure(in)#23,... 22 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\code\\University\\BigData-Project\\src\\data_preprocessing.py:104\u001b[39m, in \u001b[36mpreprocess_data\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m    101\u001b[39m check_missing_values(df)\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStep 2: Replacing NaN values with None...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m df = \u001b[43mreplace_nan_with_none\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStep 3: Dropping Unnecessary Columns...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    107\u001b[39m df = drop_high_missing_columns(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\code\\University\\BigData-Project\\src\\data_preprocessing.py:86\u001b[39m, in \u001b[36mreplace_nan_with_none\u001b[39m\u001b[34m(df, columns, exclude_types)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     85\u001b[39m         select_expr.append(F.col(c))\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mselect_expr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:3229\u001b[39m, in \u001b[36mDataFrame.select\u001b[39m\u001b[34m(self, *cols)\u001b[39m\n\u001b[32m   3184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cols: \u001b[33m\"\u001b[39m\u001b[33mColumnOrName\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mDataFrame\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   3185\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[32m   3186\u001b[39m \n\u001b[32m   3187\u001b[39m \u001b[33;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3227\u001b[39m \u001b[33;03m    +-----+---+\u001b[39;00m\n\u001b[32m   3228\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3229\u001b[39m     jdf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"isnan(Start_Time)\" due to data type mismatch: Parameter 1 requires the (\"DOUBLE\" or \"FLOAT\") type, however \"Start_Time\" has the type \"TIMESTAMP\".;\n'Project [CASE WHEN isnan(cast(ID#0 as double)) THEN cast(null as string) ELSE ID#0 END AS ID#466, CASE WHEN isnan(cast(Source#1 as double)) THEN cast(null as string) ELSE Source#1 END AS Source#467, CASE WHEN isnan(cast(Severity#2 as double)) THEN cast(null as int) ELSE Severity#2 END AS Severity#468, CASE WHEN isnan(Start_Time#3) THEN null ELSE Start_Time#3 END AS Start_Time#469, CASE WHEN isnan(End_Time#4) THEN null ELSE End_Time#4 END AS End_Time#470, CASE WHEN isnan(Start_Lat#5) THEN cast(null as double) ELSE Start_Lat#5 END AS Start_Lat#471, CASE WHEN isnan(Start_Lng#6) THEN cast(null as double) ELSE Start_Lng#6 END AS Start_Lng#472, CASE WHEN isnan(End_Lat#7) THEN cast(null as double) ELSE End_Lat#7 END AS End_Lat#473, CASE WHEN isnan(End_Lng#8) THEN cast(null as double) ELSE End_Lng#8 END AS End_Lng#474, CASE WHEN isnan(Distance(mi)#9) THEN cast(null as double) ELSE Distance(mi)#9 END AS Distance(mi)#475, CASE WHEN isnan(cast(Description#10 as double)) THEN cast(null as string) ELSE Description#10 END AS Description#476, CASE WHEN isnan(cast(Street#11 as double)) THEN cast(null as string) ELSE Street#11 END AS Street#477, CASE WHEN isnan(cast(City#12 as double)) THEN cast(null as string) ELSE City#12 END AS City#478, CASE WHEN isnan(cast(County#13 as double)) THEN cast(null as string) ELSE County#13 END AS County#479, CASE WHEN isnan(cast(State#14 as double)) THEN cast(null as string) ELSE State#14 END AS State#480, CASE WHEN isnan(cast(Zipcode#15 as double)) THEN cast(null as string) ELSE Zipcode#15 END AS Zipcode#481, CASE WHEN isnan(cast(Country#16 as double)) THEN cast(null as string) ELSE Country#16 END AS Country#482, CASE WHEN isnan(cast(Timezone#17 as double)) THEN cast(null as string) ELSE Timezone#17 END AS Timezone#483, CASE WHEN isnan(cast(Airport_Code#18 as double)) THEN cast(null as string) ELSE Airport_Code#18 END AS Airport_Code#484, CASE WHEN isnan(Weather_Timestamp#19) THEN null ELSE Weather_Timestamp#19 END AS Weather_Timestamp#485, CASE WHEN isnan(Temperature(F)#20) THEN cast(null as double) ELSE Temperature(F)#20 END AS Temperature(F)#486, CASE WHEN isnan(Wind_Chill(F)#21) THEN cast(null as double) ELSE Wind_Chill(F)#21 END AS Wind_Chill(F)#487, CASE WHEN isnan(Humidity(%)#22) THEN cast(null as double) ELSE Humidity(%)#22 END AS Humidity(%)#488, CASE WHEN isnan(Pressure(in)#23) THEN cast(null as double) ELSE Pressure(in)#23 END AS Pressure(in)#489, ... 22 more fields]\n+- Relation [ID#0,Source#1,Severity#2,Start_Time#3,End_Time#4,Start_Lat#5,Start_Lng#6,End_Lat#7,End_Lng#8,Distance(mi)#9,Description#10,Street#11,City#12,County#13,State#14,Zipcode#15,Country#16,Timezone#17,Airport_Code#18,Weather_Timestamp#19,Temperature(F)#20,Wind_Chill(F)#21,Humidity(%)#22,Pressure(in)#23,... 22 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a0313",
   "metadata": {},
   "source": [
    "## Feature Engineering \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4394ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def convert_temp_to_celsius(df, temp_col=\"Temperature(F)\", new_col=\"Temperature(C)\"):\n",
    "    return df.withColumn(new_col, (col(temp_col) - 32) * 5 / 9)\n",
    "\n",
    "df = convert_temp_to_celsius(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4974f",
   "metadata": {},
   "source": [
    "## Decriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "import folium\n",
    "\n",
    "# Sample the data for mapping (adjust fraction as needed)\n",
    "sample_map_df = df.select(\"Start_Lat\", \"Start_Lng\").dropna().sample(fraction=0.01).toPandas()\n",
    "\n",
    "# Create heatmap\n",
    "heat_data = sample_map_df[[\"Start_Lat\", \"Start_Lng\"]].values.tolist()\n",
    "center = [sample_map_df[\"Start_Lat\"].mean(), sample_map_df[\"Start_Lng\"].mean()]\n",
    "map_all = folium.Map(location=center, zoom_start=5)\n",
    "HeatMap(heat_data).add_to(map_all)\n",
    "\n",
    "# Save and display\n",
    "map_all.save(\"accidents_heatmap_all_states.html\")\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"accidents_heatmap_all_states.html\", width=\"100%\", height=\"500px\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188fc9e",
   "metadata": {},
   "source": [
    "### Severity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b20af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count accidents by severity\n",
    "severity_counts = df.groupBy(\"Severity\").count().orderBy(\"Severity\")\n",
    "\n",
    "# Convert to pandas for plotting\n",
    "severity_pd = severity_counts.toPandas().sort_values(\"Severity\")\n",
    "\n",
    "# Plot as pie chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(severity_pd['count'], labels=severity_pd['Severity'], autopct='%1.1f%%', startangle=90)\n",
    "plt.title(\"Accidents by Severity (All States)\")\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a3ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
