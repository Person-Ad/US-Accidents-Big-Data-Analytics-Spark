{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba77808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "\n",
    "from src.data_ingestion import *\n",
    "from src.data_preprocessing import *\n",
    "from src.descriptive_analytics import *\n",
    "from src.descriptive_analysis.time import *\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import NumericType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256eacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()\n",
    "df = load_data(spark, \"../../data/US_Accidents_March23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4974f",
   "metadata": {},
   "source": [
    "## Decriptive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa69a6c",
   "metadata": {},
   "source": [
    "### Time Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdc0107",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Hour` cannot be resolved. Did you mean one of the following? [`ID`, `Bump`, `Source`, `Stop`, `City`].;\n'Project ['Hour]\n+- Relation [ID#730,Source#731,Severity#732,Start_Time#733,End_Time#734,Start_Lat#735,Start_Lng#736,End_Lat#737,End_Lng#738,Distance(mi)#739,Description#740,Street#741,City#742,County#743,State#744,Zipcode#745,Country#746,Timezone#747,Airport_Code#748,Weather_Timestamp#749,Temperature(F)#750,Wind_Chill(F)#751,Humidity(%)#752,Pressure(in)#753,... 22 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m sample_fraction=\u001b[32m0.05\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sample_df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHour\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.sample(fraction=sample_fraction).toPandas()\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      6\u001b[39m sns.histplot(sample_df[\u001b[33m'\u001b[39m\u001b[33mHour\u001b[39m\u001b[33m'\u001b[39m], bins=\u001b[32m24\u001b[39m, kde=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:3229\u001b[39m, in \u001b[36mDataFrame.select\u001b[39m\u001b[34m(self, *cols)\u001b[39m\n\u001b[32m   3184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cols: \u001b[33m\"\u001b[39m\u001b[33mColumnOrName\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mDataFrame\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   3185\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[32m   3186\u001b[39m \n\u001b[32m   3187\u001b[39m \u001b[33;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3227\u001b[39m \u001b[33;03m    +-----+---+\u001b[39;00m\n\u001b[32m   3228\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3229\u001b[39m     jdf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Hour` cannot be resolved. Did you mean one of the following? [`ID`, `Bump`, `Source`, `Stop`, `City`].;\n'Project ['Hour]\n+- Relation [ID#730,Source#731,Severity#732,Start_Time#733,End_Time#734,Start_Lat#735,Start_Lng#736,End_Lat#737,End_Lng#738,Distance(mi)#739,Description#740,Street#741,City#742,County#743,State#744,Zipcode#745,Country#746,Timezone#747,Airport_Code#748,Weather_Timestamp#749,Temperature(F)#750,Wind_Chill(F)#751,Humidity(%)#752,Pressure(in)#753,... 22 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "sample_fraction=0.05\n",
    "\n",
    "sample_df = df.select(\"Hour\").sample(fraction=sample_fraction).toPandas()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(sample_df['Hour'], bins=24, kde=True)\n",
    "plt.title('Accidents by Hour of Day (All States)')\n",
    "plt.xlabel('Hour of Day (0-23)')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.select(\"Day_of_Week\").sample(fraction=sample_fraction).toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Day_of_Week', data=sample_df)\n",
    "plt.title('Accidents by Day of Week (All States)')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.xticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bfe4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.select(\"Month\", \"Season\").sample(fraction=sample_fraction).toPandas()\n",
    "\n",
    "# Plot 1: Accidents by Month\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Month', data=sample_df)\n",
    "plt.title('Accidents by Month (All States)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.xticks(range(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot 2: Accidents by Season\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Season', data=sample_df, order=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "plt.title('Accidents by Season (All States)')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d66e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_hour = df.groupBy(\"Hour\", \"Severity\").count().toPandas()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.catplot(x=\"Hour\", y=\"count\", hue=\"Severity\", kind=\"bar\", data=severity_hour, height=6, aspect=2)\n",
    "plt.title('Accident Severity by Hour of Day (All States)')\n",
    "plt.xlabel('Hour of Day (0-23)')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df670b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_df = df.groupBy(\"Day_of_Week\", \"Hour\").count().toPandas()\n",
    "heatmap_data = heat_df.pivot(index='Day_of_Week', columns='Hour', values='count').fillna(0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data, cmap='YlOrRd')\n",
    "plt.title('Heatmap of Accidents by Hour and Day of Week (All States)')\n",
    "plt.xlabel('Hour of Day (0-23)')\n",
    "plt.ylabel('Day of Week')\n",
    "plt.yticks(ticks=[0.5+i for i in range(7)], labels=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e963849",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df = df.groupBy(\"Year\").count().toPandas()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Year', y='count', data=year_df)\n",
    "plt.title('Accidents by Year (All States)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fraction=0.1, top_n_states=5\n",
    "\n",
    "# Preprocess temporal features\n",
    "df = df.withColumn(\"Hour\", F.hour(\"Start_Time\")) \\\n",
    "        .withColumn(\n",
    "            \"Severe_Accident\",\n",
    "            F.when(F.col(\"Severity\").isin([3, 4]), 1).otherwise(0)\n",
    "        )\n",
    "\n",
    "# Define twilight columns\n",
    "twilight_cols = ['Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n",
    "\n",
    "# Drop rows with null values in relevant columns\n",
    "df = df.dropna(subset=twilight_cols + ['Hour', 'State', 'Severity'])\n",
    "\n",
    "# Sample data to reduce memory usage\n",
    "sample_df = df.sample(fraction=sample_fraction).toPandas()\n",
    "\n",
    "# Identify top N states by accident count\n",
    "top_states = sample_df['State'].value_counts().head(top_n_states).index.tolist()\n",
    "\n",
    "# Plot 1: Distribution of accidents by Sunrise_Sunset\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Sunrise_Sunset', data=sample_df)\n",
    "plt.title('Accidents by Day/Night (Sunrise_Sunset) - US')\n",
    "plt.xlabel('Day / Night')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Severity by Twilight Condition\n",
    "sample_df['Twilight_Condition'] = sample_df.apply(\n",
    "    lambda row: 'Twilight' if (\n",
    "        (row['Sunrise_Sunset'] == 'Day' and row['Civil_Twilight'] == 'Night') or\n",
    "        (row['Sunrise_Sunset'] == 'Night' and row['Civil_Twilight'] == 'Day')\n",
    "    ) else row['Sunrise_Sunset'],  # Corrected typo\n",
    "    axis=1\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Twilight_Condition', hue='Severity', data=sample_df, order=['Day', 'Night', 'Twilight'])\n",
    "plt.title('Accident Severity by Twilight Condition - US')\n",
    "plt.xlabel('Condition (Day, Night, Twilight)')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28171c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Accidents during twilight transitions\n",
    "sample_df['Twilight_Transition'] = (\n",
    "    (sample_df['Sunrise_Sunset'] == 'Day') & (sample_df['Civil_Twilight'] == 'Night')\n",
    ") | (\n",
    "    (sample_df['Sunrise_Sunset'] == 'Night') & (sample_df['Civil_Twilight'] == 'Day')\n",
    ")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Twilight_Transition', data=sample_df)\n",
    "plt.title('Accidents during Twilight Transitions (Sunrise_Sunset vs Civil_Twilight) - US')\n",
    "plt.xlabel('Twilight Transition (True = Transition, False = No Transition)')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee673a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot 4: Accidents by Top States and Twilight Condition\n",
    "state_df = sample_df[sample_df['State'].isin(top_states)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='State', hue='Twilight_Condition', data=state_df, order=top_states)\n",
    "plt.title(f'Accidents by Top {top_n_states} States and Twilight Condition - US')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary: Accident counts and severity by Twilight Condition\n",
    "twilight_summary = sample_df.groupby('Twilight_Condition').agg({\n",
    "    'Severity': ['count', 'mean'],\n",
    "    'Severe_Accident': 'mean',\n",
    "    'Hour': 'mean'\n",
    "}).reset_index()\n",
    "twilight_summary.columns = ['Twilight_Condition', 'Accident_Count', 'Avg_Severity', \n",
    "                            'Prop_Severe_Accidents', 'Avg_Hour']\n",
    "twilight_summary['Prop_Severe_Accidents'] = twilight_summary['Prop_Severe_Accidents'] * 100  # Convert to percentage\n",
    "\n",
    "print(\"Statistical Summary by Twilight Condition (US):\")\n",
    "print(twilight_summary)\n",
    "\n",
    "# State-Level Summary: Accident counts and severe accidents by top states and Twilight Condition\n",
    "state_summary = sample_df[sample_df['State'].isin(top_states)].groupby(['State', 'Twilight_Condition']).agg({\n",
    "    'Severity': ['count', 'mean'],\n",
    "    'Severe_Accident': 'mean'\n",
    "}).reset_index()\n",
    "state_summary.columns = ['State', 'Twilight_Condition', 'Accident_Count', 'Avg_Severity', 'Prop_Severe_Accidents']\n",
    "state_summary['Prop_Severe_Accidents'] = state_summary['Prop_Severe_Accidents'] * 100  # Convert to percentage\n",
    "\n",
    "print(f\"\\nStatistical Summary by Top {top_n_states} States and Twilight Condition (US):\")\n",
    "print(state_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a47f7",
   "metadata": {},
   "source": [
    "### **Time Analysis Insights**\n",
    "\n",
    "1. **Winter and Fall** experience more accidents due to hazardous weather, such as snow, ice, and reduced daylight.\n",
    "2. **Spring and Summer** see fewer accidents, with **June** being the safest month.\n",
    "3. **Rush hours** (7-9 AM and 3-6 PM) have the highest accident frequency due to increased traffic.\n",
    "4. **Late-night hours** (around 2 AM) show the lowest accident frequency.\n",
    "5. **Weekdays** have more accidents than weekends, with **Friday** being the peak day.\n",
    "6. **December, January, and November** are the most accident-prone months, likely influenced by winter and holiday factors.\n",
    "7. Accident counts **steadily grew** from 2016 to 2022, nearly quadrupling in this period, indicating an increase in accident frequency.\n",
    "8. The **sharp drop in 2023 accident counts** is likely due to incomplete data (up to March), not a true decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf5598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
