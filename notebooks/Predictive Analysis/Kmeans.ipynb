{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba77808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import findspark\n",
    "findspark.init() # Find Spark installation\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType, StringType, BooleanType, TimestampType, StructType, StructField\n",
    "\n",
    "# For ML tasks (even if demonstrating MapReduce concepts, preprocessing often uses MLlib)\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, Bucketizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix # For potential matrix operations\n",
    "\n",
    "import math\n",
    "import heapq\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "\n",
    "from src.data_ingestion import *\n",
    "from src.data_preprocessing import *\n",
    "from src.descriptive_analytics import *\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256eacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()\n",
    "df = load_data(spark, \"../../data/US_Accidents_March23.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e929459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "| ID| Source|Severity|         Start_Time|           End_Time|        Start_Lat|         Start_Lng|End_Lat|End_Lng|Distance(mi)|         Description|              Street|        City|    County|State|   Zipcode|Country|  Timezone|Airport_Code|  Weather_Timestamp|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Precipitation(in)|Weather_Condition|Amenity| Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station| Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|hour_of_day|day_of_week|month|year|weather_condition_cat|is_night|severe_accident|\n",
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "|A-1|Source2|       3|2016-02-08 05:46:00|2016-02-08 11:00:00|        39.865147|        -84.058723|   NULL|   NULL|        0.01|Right lane blocke...|              I-70 E|      Dayton|Montgomery|   OH|     45424|     US|US/Eastern|        KFFO|2016-02-08 05:58:00|          36.9|         NULL|       91.0|       29.68|          10.0|          Calm|           NULL|             0.02|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                Night|          5|          2|    2|2016|                    3|       1|              1|\n",
      "|A-2|Source2|       2|2016-02-08 06:07:59|2016-02-08 06:37:59|39.92805900000001|        -82.831184|   NULL|   NULL|        0.01|Accident on Brice...|            Brice Rd|Reynoldsburg|  Franklin|   OH|43068-3402|     US|US/Eastern|        KCMH|2016-02-08 05:51:00|          37.9|         NULL|      100.0|       29.65|          10.0|          Calm|           NULL|              0.0|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                  Day|          6|          2|    2|2016|                    3|       0|              0|\n",
      "|A-3|Source2|       2|2016-02-08 06:49:27|2016-02-08 07:19:27|        39.063148|        -84.032608|   NULL|   NULL|        0.01|Accident on OH-32...|      State Route 32|Williamsburg|  Clermont|   OH|     45176|     US|US/Eastern|        KI69|2016-02-08 06:56:00|          36.0|         33.3|      100.0|       29.67|          10.0|            SW|            3.5|             NULL|         Overcast|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|         Night|         Night|              Day|                  Day|          6|          2|    2|2016|                    3|       0|              0|\n",
      "|A-4|Source2|       3|2016-02-08 07:23:34|2016-02-08 07:53:34|        39.747753|-84.20558199999998|   NULL|   NULL|        0.01|Accident on I-75 ...|              I-75 S|      Dayton|Montgomery|   OH|     45417|     US|US/Eastern|        KDAY|2016-02-08 07:38:00|          35.1|         31.0|       96.0|       29.64|           9.0|            SW|            4.6|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|           Day|              Day|                  Day|          7|          2|    2|2016|                    3|       0|              1|\n",
      "|A-5|Source2|       2|2016-02-08 07:39:07|2016-02-08 08:09:07|        39.627781|        -84.188354|   NULL|   NULL|        0.01|Accident on McEwe...|Miamisburg Center...|      Dayton|Montgomery|   OH|     45459|     US|US/Eastern|        KMGY|2016-02-08 07:53:00|          36.0|         33.3|       89.0|       29.65|           6.0|            SW|            3.5|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|           Day|           Day|              Day|                  Day|          7|          2|    2|2016|                    3|       0|              0|\n",
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, dayofweek, month, year, when\n",
    "\n",
    "# Extract time-based features from Start_Time\n",
    "df = df.withColumn(\"hour_of_day\", hour(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"month\", month(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"year\", year(df[\"Start_Time\"]))\n",
    "\n",
    "# Handle categorical features - Weather_Condition\n",
    "df = df.withColumn(\"weather_condition_cat\", when(df[\"Weather_Condition\"] == \"Clear\", 0)\n",
    "                                            .when(df[\"Weather_Condition\"] == \"Rain\", 1)\n",
    "                                            .when(df[\"Weather_Condition\"] == \"Snow\", 2)\n",
    "                                            .otherwise(3))\n",
    "\n",
    "# Add a binary feature for day/night based on the time of the accident\n",
    "df = df.withColumn(\"is_night\", when((df[\"hour_of_day\"] >= 18) | (df[\"hour_of_day\"] < 6), 1).otherwise(0))\n",
    "\n",
    "# Create a boolean flag for severe accidents (Severity >= 3)\n",
    "df = df.withColumn(\"severe_accident\", when(df[\"Severity\"] >= 3, 1).otherwise(0))\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c8b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in columns like temperature, wind speed with the mean or median\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=[\"Temperature(F)\", \"Wind_Speed(mph)\", \"Humidity(%)\"], outputCols=[\"Temperature_imputed\", \"Wind_Speed_imputed\", \"Humidity_imputed\"])\n",
    "df = imputer.fit(df).transform(df)\n",
    "\n",
    "# Drop rows with missing target variables (if any)\n",
    "df = df.dropna(subset=[\"Severity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f31cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97d28dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[ 31.27814441 -82.32015619]\n",
      "[  40.54451899 -121.54860482]\n",
      "[ 40.02010468 -77.31986112]\n",
      "[ 36.17015069 -94.43016175]\n",
      "[  34.51816798 -116.51956581]\n",
      "+-----------------+------------------+-------+\n",
      "|        Start_Lat|         Start_Lng|cluster|\n",
      "+-----------------+------------------+-------+\n",
      "|        39.865147|        -84.058723|      2|\n",
      "|39.92805900000001|        -82.831184|      2|\n",
      "|        39.063148|        -84.032608|      2|\n",
      "|        39.747753|-84.20558199999998|      2|\n",
      "|        39.627781|        -84.188354|      2|\n",
      "+-----------------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Assemble the geographical features (latitude and longitude) into a single vector column\n",
    "geo_assembler = VectorAssembler(inputCols=[\"Start_Lat\", \"Start_Lng\"], outputCol=\"geo_features\")\n",
    "df = geo_assembler.transform(df)\n",
    "\n",
    "# Train a KMeans model (KMeans++ initialization is used by default)\n",
    "kmeans = KMeans(k=5, featuresCol=\"geo_features\", predictionCol=\"cluster\")\n",
    "kmeans_model = kmeans.fit(df)\n",
    "\n",
    "# Make predictions and assign clusters to the data\n",
    "df = kmeans_model.transform(df)\n",
    "\n",
    "# Show the cluster centers\n",
    "print(\"Cluster Centers: \")\n",
    "for center in kmeans_model.clusterCenters():\n",
    "    print(center)\n",
    "\n",
    "# Show the data with assigned clusters\n",
    "df.select(\"Start_Lat\", \"Start_Lng\", \"cluster\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71226b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For KMeans, you can visualize the clusters' centers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convert cluster centers into a numpy array for visualization\n",
    "cluster_centers = np.array(kmeans_model.clusterCenters())\n",
    "\n",
    "# Plot the geographical clusters (if you want to visualize the clusters on a map)\n",
    "plt.scatter(df.select(\"Start_Lat\").toPandas(), df.select(\"Start_Lng\").toPandas(), c=df.select(\"cluster\").toPandas(), cmap=\"viridis\")\n",
    "plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], marker=\"x\", color=\"red\", s=100, label=\"Cluster Centers\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.title(\"Accident Hotspots and Cluster Centers\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
