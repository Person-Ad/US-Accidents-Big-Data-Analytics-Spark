{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba77808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import findspark\n",
    "findspark.init() # Find Spark installation\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# For ML tasks (even if demonstrating MapReduce concepts, preprocessing often uses MLlib)\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, Bucketizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix # For potential matrix operations\n",
    "\n",
    "import math\n",
    "import heapq\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "\n",
    "from src.data_ingestion import *\n",
    "from src.data_preprocessing import *\n",
    "from src.descriptive_analytics import *\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256eacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()\n",
    "df = load_data(spark, \"../../data/US_Accidents_March23.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e929459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "| ID| Source|Severity|         Start_Time|           End_Time|        Start_Lat|         Start_Lng|End_Lat|End_Lng|Distance(mi)|         Description|              Street|        City|    County|State|   Zipcode|Country|  Timezone|Airport_Code|  Weather_Timestamp|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Precipitation(in)|Weather_Condition|Amenity| Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station| Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|hour_of_day|day_of_week|month|year|weather_condition_cat|is_night|severe_accident|\n",
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "|A-1|Source2|       3|2016-02-08 05:46:00|2016-02-08 11:00:00|        39.865147|        -84.058723|   NULL|   NULL|        0.01|Right lane blocke...|              I-70 E|      Dayton|Montgomery|   OH|     45424|     US|US/Eastern|        KFFO|2016-02-08 05:58:00|          36.9|         NULL|       91.0|       29.68|          10.0|          Calm|           NULL|             0.02|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                Night|          5|          2|    2|2016|                    3|       1|              1|\n",
      "|A-2|Source2|       2|2016-02-08 06:07:59|2016-02-08 06:37:59|39.92805900000001|        -82.831184|   NULL|   NULL|        0.01|Accident on Brice...|            Brice Rd|Reynoldsburg|  Franklin|   OH|43068-3402|     US|US/Eastern|        KCMH|2016-02-08 05:51:00|          37.9|         NULL|      100.0|       29.65|          10.0|          Calm|           NULL|              0.0|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                  Day|          6|          2|    2|2016|                    3|       0|              0|\n",
      "|A-3|Source2|       2|2016-02-08 06:49:27|2016-02-08 07:19:27|        39.063148|        -84.032608|   NULL|   NULL|        0.01|Accident on OH-32...|      State Route 32|Williamsburg|  Clermont|   OH|     45176|     US|US/Eastern|        KI69|2016-02-08 06:56:00|          36.0|         33.3|      100.0|       29.67|          10.0|            SW|            3.5|             NULL|         Overcast|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|         Night|         Night|              Day|                  Day|          6|          2|    2|2016|                    3|       0|              0|\n",
      "|A-4|Source2|       3|2016-02-08 07:23:34|2016-02-08 07:53:34|        39.747753|-84.20558199999998|   NULL|   NULL|        0.01|Accident on I-75 ...|              I-75 S|      Dayton|Montgomery|   OH|     45417|     US|US/Eastern|        KDAY|2016-02-08 07:38:00|          35.1|         31.0|       96.0|       29.64|           9.0|            SW|            4.6|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|           Day|              Day|                  Day|          7|          2|    2|2016|                    3|       0|              1|\n",
      "|A-5|Source2|       2|2016-02-08 07:39:07|2016-02-08 08:09:07|        39.627781|        -84.188354|   NULL|   NULL|        0.01|Accident on McEwe...|Miamisburg Center...|      Dayton|Montgomery|   OH|     45459|     US|US/Eastern|        KMGY|2016-02-08 07:53:00|          36.0|         33.3|       89.0|       29.65|           6.0|            SW|            3.5|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|           Day|           Day|              Day|                  Day|          7|          2|    2|2016|                    3|       0|              0|\n",
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, dayofweek, month, year, when\n",
    "\n",
    "# Extract time-based features from Start_Time\n",
    "df = df.withColumn(\"hour_of_day\", hour(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"month\", month(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"year\", year(df[\"Start_Time\"]))\n",
    "\n",
    "# Handle categorical features - Weather_Condition\n",
    "df = df.withColumn(\"weather_condition_cat\", when(df[\"Weather_Condition\"] == \"Clear\", 0)\n",
    "                                            .when(df[\"Weather_Condition\"] == \"Rain\", 1)\n",
    "                                            .when(df[\"Weather_Condition\"] == \"Snow\", 2)\n",
    "                                            .otherwise(3))\n",
    "\n",
    "# Add a binary feature for day/night based on the time of the accident\n",
    "df = df.withColumn(\"is_night\", when((df[\"hour_of_day\"] >= 18) | (df[\"hour_of_day\"] < 6), 1).otherwise(0))\n",
    "\n",
    "# Create a boolean flag for severe accidents (Severity >= 3)\n",
    "df = df.withColumn(\"severe_accident\", when(df[\"Severity\"] >= 3, 1).otherwise(0))\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c8b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in columns like temperature, wind speed with the mean or median\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=[\"Temperature(F)\", \"Wind_Speed(mph)\", \"Humidity(%)\"], outputCols=[\"Temperature_imputed\", \"Wind_Speed_imputed\", \"Humidity_imputed\"])\n",
    "df = imputer.fit(df).transform(df)\n",
    "\n",
    "# Drop rows with missing target variables (if any)\n",
    "df = df.dropna(subset=[\"Severity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f31cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97d28dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Assemble features into a single vector column\n",
    "feature_cols = [\"hour_of_day\", \"day_of_week\", \"month\", \"Temperature_imputed\", \"Wind_Speed_imputed\", \"Humidity_imputed\", \"is_night\", \"weather_condition_cat\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestClassifier(labelCol=\"severe_accident\", featuresCol=\"features\", numTrees=100)\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"severe_accident\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff01c706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "                 feature  importance\n",
      "7  weather_condition_cat    0.595962\n",
      "4     Wind_Speed_imputed    0.215379\n",
      "1            day_of_week    0.076574\n",
      "2                  month    0.058833\n",
      "0            hour_of_day    0.022498\n",
      "6               is_night    0.016043\n",
      "5       Humidity_imputed    0.010184\n",
      "3    Temperature_imputed    0.004527\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from the trained model\n",
    "feature_importances = model.featureImportances\n",
    "\n",
    "# Convert feature importances to a Pandas DataFrame for easy viewing\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": feature_importances.toArray()  # Convert SparseVector to dense array\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "025a0410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"severe_accident\", rawPredictionCol=\"prediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "484d178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.80\n",
      "Recall: 0.81\n",
      "F1-Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"severe_accident\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"severe_accident\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"severe_accident\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08240ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create a geospatial feature by combining latitude and longitude\n",
    "geo_assembler = VectorAssembler(inputCols=[\"Start_Lat\", \"Start_Lng\"], outputCol=\"geo_features\")\n",
    "df = geo_assembler.transform(df)\n",
    "\n",
    "# KMeans clustering to identify accident hotspots\n",
    "kmeans = KMeans(k=5, featuresCol=\"geo_features\", predictionCol=\"cluster\")\n",
    "model = kmeans.fit(df)\n",
    "df = model.transform(df)\n",
    "\n",
    "# Show the clustered data\n",
    "df.select(\"Start_Lat\", \"Start_Lng\", \"cluster\").show(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
