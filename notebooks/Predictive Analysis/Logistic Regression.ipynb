{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba77808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import findspark\n",
    "findspark.init() # Find Spark installation\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType, StringType, BooleanType, TimestampType, StructType, StructField\n",
    "\n",
    "# For ML tasks (even if demonstrating MapReduce concepts, preprocessing often uses MLlib)\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, Bucketizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix # For potential matrix operations\n",
    "\n",
    "import math\n",
    "import heapq\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "\n",
    "from src.data_ingestion import *\n",
    "from src.data_preprocessing import *\n",
    "from src.descriptive_analytics import *\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256eacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()\n",
    "df = load_data(spark, \"../../data/US_Accidents_March23.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e929459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "| ID| Source|Severity|         Start_Time|           End_Time|        Start_Lat|         Start_Lng|End_Lat|End_Lng|Distance(mi)|         Description|              Street|        City|    County|State|   Zipcode|Country|  Timezone|Airport_Code|  Weather_Timestamp|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Precipitation(in)|Weather_Condition|Amenity| Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station| Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|hour_of_day|day_of_week|month|year|weather_condition_cat|is_night|severe_accident|\n",
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "|A-1|Source2|       3|2016-02-08 05:46:00|2016-02-08 11:00:00|        39.865147|        -84.058723|   NULL|   NULL|        0.01|Right lane blocke...|              I-70 E|      Dayton|Montgomery|   OH|     45424|     US|US/Eastern|        KFFO|2016-02-08 05:58:00|          36.9|         NULL|       91.0|       29.68|          10.0|          Calm|           NULL|             0.02|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                Night|          5|          2|    2|2016|                    3|       1|              1|\n",
      "|A-2|Source2|       2|2016-02-08 06:07:59|2016-02-08 06:37:59|39.92805900000001|        -82.831184|   NULL|   NULL|        0.01|Accident on Brice...|            Brice Rd|Reynoldsburg|  Franklin|   OH|43068-3402|     US|US/Eastern|        KCMH|2016-02-08 05:51:00|          37.9|         NULL|      100.0|       29.65|          10.0|          Calm|           NULL|              0.0|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                  Day|          6|          2|    2|2016|                    3|       0|              0|\n",
      "|A-3|Source2|       2|2016-02-08 06:49:27|2016-02-08 07:19:27|        39.063148|        -84.032608|   NULL|   NULL|        0.01|Accident on OH-32...|      State Route 32|Williamsburg|  Clermont|   OH|     45176|     US|US/Eastern|        KI69|2016-02-08 06:56:00|          36.0|         33.3|      100.0|       29.67|          10.0|            SW|            3.5|             NULL|         Overcast|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|         Night|         Night|              Day|                  Day|          6|          2|    2|2016|                    3|       0|              0|\n",
      "|A-4|Source2|       3|2016-02-08 07:23:34|2016-02-08 07:53:34|        39.747753|-84.20558199999998|   NULL|   NULL|        0.01|Accident on I-75 ...|              I-75 S|      Dayton|Montgomery|   OH|     45417|     US|US/Eastern|        KDAY|2016-02-08 07:38:00|          35.1|         31.0|       96.0|       29.64|           9.0|            SW|            4.6|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|           Day|              Day|                  Day|          7|          2|    2|2016|                    3|       0|              1|\n",
      "|A-5|Source2|       2|2016-02-08 07:39:07|2016-02-08 08:09:07|        39.627781|        -84.188354|   NULL|   NULL|        0.01|Accident on McEwe...|Miamisburg Center...|      Dayton|Montgomery|   OH|     45459|     US|US/Eastern|        KMGY|2016-02-08 07:53:00|          36.0|         33.3|       89.0|       29.65|           6.0|            SW|            3.5|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|           Day|           Day|              Day|                  Day|          7|          2|    2|2016|                    3|       0|              0|\n",
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+-----------+-----------+-----+----+---------------------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, dayofweek, month, year, when\n",
    "\n",
    "# Extract time-based features from Start_Time\n",
    "df = df.withColumn(\"hour_of_day\", hour(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"month\", month(df[\"Start_Time\"]))\n",
    "df = df.withColumn(\"year\", year(df[\"Start_Time\"]))\n",
    "\n",
    "# Handle categorical features - Weather_Condition\n",
    "df = df.withColumn(\"weather_condition_cat\", when(df[\"Weather_Condition\"] == \"Clear\", 0)\n",
    "                                            .when(df[\"Weather_Condition\"] == \"Rain\", 1)\n",
    "                                            .when(df[\"Weather_Condition\"] == \"Snow\", 2)\n",
    "                                            .otherwise(3))\n",
    "\n",
    "# Add a binary feature for day/night based on the time of the accident\n",
    "df = df.withColumn(\"is_night\", when((df[\"hour_of_day\"] >= 18) | (df[\"hour_of_day\"] < 6), 1).otherwise(0))\n",
    "\n",
    "# Create a boolean flag for severe accidents (Severity >= 3)\n",
    "df = df.withColumn(\"severe_accident\", when(df[\"Severity\"] >= 3, 1).otherwise(0))\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c8b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in columns like temperature, wind speed with the mean or median\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=[\"Temperature(F)\", \"Wind_Speed(mph)\", \"Humidity(%)\"], outputCols=[\"Temperature_imputed\", \"Wind_Speed_imputed\", \"Humidity_imputed\"])\n",
    "df = imputer.fit(df).transform(df)\n",
    "\n",
    "# Drop rows with missing target variables (if any)\n",
    "df = df.dropna(subset=[\"Severity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f31cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97d28dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.81\n",
      "Precision: 0.73\n",
      "Recall: 0.81\n",
      "F1-Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Assemble features into a single vector column for logistic regression\n",
    "logistic_features = [\"hour_of_day\", \"day_of_week\", \"month\", \"Temperature_imputed\", \"Wind_Speed_imputed\", \"Humidity_imputed\", \"is_night\", \"weather_condition_cat\"]\n",
    "assembler = VectorAssembler(inputCols=logistic_features, outputCol=\"features\")\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)\n",
    "\n",
    "# Train a Logistic Regression model to predict severe accidents\n",
    "lr_model = LogisticRegression(labelCol=\"severe_accident\", featuresCol=\"features\")\n",
    "model = lr_model.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "logistic_predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model (Accuracy, Precision, Recall, F1-Score)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"severe_accident\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(logistic_predictions)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Optional: Evaluate Precision, Recall, and F1 Score\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"severe_accident\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"severe_accident\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"severe_accident\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "precision = precision_evaluator.evaluate(logistic_predictions)\n",
    "recall = recall_evaluator.evaluate(logistic_predictions)\n",
    "f1 = f1_evaluator.evaluate(logistic_predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528936af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the predictions and actual values for further analysis\n",
    "predictions_df = logistic_predictions.select(\"severe_accident\", \"prediction\").toPandas()\n",
    "\n",
    "# Visualizing the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(predictions_df[\"severe_accident\"], predictions_df[\"prediction\"])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Severe\", \"Severe\"], yticklabels=[\"Non-Severe\", \"Severe\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
